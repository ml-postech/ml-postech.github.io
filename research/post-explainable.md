---
title: Post-hoc Explainable AI with LLMs 
advisor: advisor-jungseul-ok
mentors:
- student-jaechang-kim
---
Post-hoc explainability is essential for improving the transparency and trustworthiness of machine learning models. Traditional methods, such as saliency maps, provide valuable insights into model decisions but often require domain expertise to interpret effectively. With the rise of LLMs, natural language explanations have emerged as a more accessible and flexible alternative, allowing users to engage with model reasoning in an intuitive way. This project explores how LLMs can generate contextually rich and faithful explanations while maintaining alignment with the underlying modelâ€™s decision-making process. We investigate techniques that enhance interpretability through structured reasoning and interactive dialogue, ultimately contributing to the development of more transparent and user-friendly AI systems.
