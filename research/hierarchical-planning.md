---
title: Hierarchical Planning for Efficient Exploration
advisor: jungseul-ok
mentor: youngsik-yoon
---
Hierarchical planning is essential for efficient exploration in Reinforcement Learning (RL), as it helps agents structure decisions across different levels. By focusing on high-level goals before refining low-level actions, it enables smarter exploration in complex environments. For example, in path planning tasks, hierarchical strategies can optimize route selection, while in LLM-based planning, they can help structure tasks into manageable subgoals. This approach is particularly effective in long-horizon tasks and sparse reward settings, where traditional methods often lead to inefficient exploration and slow learning. In this study, we explore how hierarchical planning can accelerate exploration and improve learning efficiency in RL.
